from controller import Supervisor
import numpy as np
import torch
from stable_baselines3 import PPO
import math
import time
import socket


class RLSupervisor(Supervisor):
    def __init__(self):
        super().__init__()
        self.timestep = int(self.getBasicTimeStep())

        # ë¡œë´‡ ë…¸ë“œ ì •ì˜
        self.robot_node = self.getFromDef("ROBOT_NAME")
        if self.robot_node is None:
            print("âŒ ë¡œë´‡ ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. DEF ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")
            exit(1)

        self.robot_translation = self.robot_node.getField("translation")
        self.robot_rotation = self.robot_node.getField("rotation")


        # ëª©í‘œ ìœ„ì¹˜
        self.goal_pos = np.array([18.0, 1.0])
        self.step_size = 0.2  # Grid ë‹¨ìœ„

        # PPO ëª¨ë¸ ë¡œë“œ
        self.rl_model = PPO.load("RL_grid_test.zip")


        # ì†Œì¼“ ì´ˆê¸°í™” (ìˆ˜ì‹ ì€ run() ì•ˆì—ì„œ)
        self.conn = None
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.sock.bind(('127.0.0.1', 9999))
        self.sock.listen(1)
        print("ğŸŸ¢ YOLO ë°ì´í„° ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")

    def run(self):
        goal_reached = False

        while self.step(self.timestep) != -1:
            # ì—°ê²°ì´ ì—†ìœ¼ë©´ ê³„ì† ëŒ€ê¸°
            if self.conn is None:
                try:
                    self.sock.settimeout(0.1)
                    self.conn, addr = self.sock.accept()
                    self.conn.settimeout(0.01)
                    print(f"ğŸ”— YOLO ì—°ê²°ë¨: {addr}")
                except socket.timeout:
                    continue
                continue  # ì—°ê²° ì§í›„ ìŠ¤í‚µ

            try:
                data = self.conn.recv(1024).decode()
                if not data:
                    continue

                print(f"ğŸ“© ë°›ì€ ë°ì´í„°: {data}")
                rx, ry, px, py = map(float, data.strip().split(","))

                robot_pos = np.array([rx, ry])
                person_pos = np.array([px, py])

                # PPO ì…ë ¥ ê´€ì¸¡ê°’ êµ¬ì„±
                obs = np.concatenate((robot_pos, person_pos, self.goal_pos)).astype(np.float32).reshape(1, -1)
                print(f"ğŸ“¥ obs: {obs}")

                # í–‰ë™ ì˜ˆì¸¡ ë° ì´ë™
                action, _ = self.rl_model.predict(obs)
                move = self._convert_action_to_vector(action[0])
                print(f"ğŸ¤– action: {action[0]}, move: {move}")

                new_pos = robot_pos + move * self.step_size
                print(f"ğŸ“¦ ë¡œë´‡ ìœ„ì¹˜ ì—…ë°ì´íŠ¸: ({new_pos[0]:.2f}, {new_pos[1]:.2f}, 0.2)")

                self.robot_translation.setSFVec3f([new_pos[0], new_pos[1], 0.2])
                heading = math.atan2(move[1], move[0])
                self.robot_rotation.setSFRotation([0, 0, 1, heading])

                # ëª©í‘œ ë„ë‹¬ ì²´í¬
                if not goal_reached and np.linalg.norm(robot_pos - self.goal_pos) < 0.5:
                    print(f"ğŸ¯ ëª©í‘œ ë„ë‹¬! ìœ„ì¹˜: ({rx:.2f}, {ry:.2f})")
                    goal_reached = True

                time.sleep(0.05)  # ì´ë™ ì†ë„ ì¡°ì ˆ
            except socket.timeout:
                continue
            except Exception as e:
                print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}")
                break

    def _convert_action_to_vector(self, action):
        directions = {
            0: np.array([0, 1]),    # â†‘
            1: np.array([0, -1]),   # â†“
            2: np.array([-1, 0]),   # â†
            3: np.array([1, 0])     # â†’
        }
        return directions.get(action, np.array([0, 0]))


if __name__ == "__main__":
    supervisor = RLSupervisor()
    supervisor.run()

